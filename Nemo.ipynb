{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc-Amwbxt9fp",
        "outputId": "dee6f194-89c0-42ea-e528-5e22218733c5"
      },
      "outputs": [],
      "source": [
        "# # prompt: mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30f83388",
        "outputId": "6de28616-712e-448a-a67d-bfa2ae16409b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Cython\n",
            "  Downloading cython-3.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: packaging in /home/kelechi/miniconda3/envs/bio_ramp/lib/python3.9/site-packages (25.0)\n",
            "Downloading cython-3.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Cython\n",
            "Successfully installed Cython-3.1.1\n",
            "\u001b[33mDEPRECATION: git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[asr] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nemo_toolkit[asr]\n",
            "  Cloning https://github.com/NVIDIA/NeMo.git (to revision main) to /tmp/pip-install-74f_odzx/nemo-toolkit_49fc447188f54b8ea1de5f3f13147ece\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/NeMo.git /tmp/pip-install-74f_odzx/nemo-toolkit_49fc447188f54b8ea1de5f3f13147ece\n",
            "  Resolved https://github.com/NVIDIA/NeMo.git to commit 64625d4814c87d545efa533fdc6cf6b62105c23e\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: fsspec==2024.12.0 in /home/kelechi/miniconda3/envs/bio_ramp/lib/python3.9/site-packages (from nemo_toolkit[asr]) (2024.12.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.24 in /home/kelechi/miniconda3/envs/bio_ramp/lib/python3.9/site-packages (from nemo_toolkit[asr]) (0.30.2)\n",
            "INFO: pip is looking at multiple versions of nemo-toolkit[asr] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.61.0 Requires-Python >=3.10; 0.61.0rc1 Requires-Python >=3.10; 0.61.0rc2 Requires-Python >=3.10; 0.61.1rc1 Requires-Python >=3.10; 0.61.2 Requires-Python >=3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numba==0.61.0 (from nemo-toolkit[asr]) (from versions: 0.1, 0.2, 0.3, 0.5.0, 0.6.0, 0.7.0, 0.7.1, 0.7.2, 0.8.0, 0.8.1, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.12.2, 0.13.0, 0.13.2, 0.13.3, 0.13.4, 0.14.0, 0.15.1, 0.16.0, 0.17.0, 0.18.1, 0.18.2, 0.19.1, 0.19.2, 0.20.0, 0.21.0, 0.22.0, 0.22.1, 0.23.0, 0.23.1, 0.24.0, 0.25.0, 0.26.0, 0.27.0, 0.28.1, 0.29.0, 0.30.0, 0.30.1, 0.31.0, 0.32.0, 0.33.0, 0.34.0, 0.35.0, 0.36.1, 0.36.2, 0.37.0, 0.38.0, 0.38.1, 0.39.0, 0.40.0, 0.40.1, 0.41.0, 0.42.0, 0.42.1, 0.43.0, 0.43.1, 0.44.0, 0.44.1, 0.45.0, 0.45.1, 0.46.0, 0.47.0, 0.48.0, 0.49.0, 0.49.1rc1, 0.49.1, 0.50.0rc1, 0.50.0, 0.50.1, 0.51.0rc1, 0.51.0, 0.51.1, 0.51.2, 0.52.0rc2, 0.53.0rc1.post1, 0.53.0rc2, 0.53.0rc3, 0.53.0, 0.53.1, 0.54.0rc2, 0.54.0rc3, 0.54.0, 0.54.1rc1, 0.54.1, 0.55.0rc1, 0.55.0, 0.55.1, 0.55.2, 0.56.0rc1, 0.56.0, 0.56.2, 0.56.3, 0.56.4, 0.57.0rc1, 0.57.0, 0.57.1rc1, 0.57.1, 0.58.0rc1, 0.58.0rc2, 0.58.0, 0.58.1, 0.59.0rc1, 0.59.0, 0.59.1, 0.60.0rc1, 0.60.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for numba==0.61.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !apt-get update && apt-get install -y libsndfile1 ffmpeg\n",
        "!pip install Cython packaging\n",
        "!pip install git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[asr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoJXbooloEbK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import getpass\n",
        "import torch\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KpigRBluQv8"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/data/afrispeech_dialog_v1_47.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYtW9PEYxLfT",
        "outputId": "ca315d9e-9d2c-4090-96cb-a57349556568"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(49, 11)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "6SsXYzL0xe9X",
        "outputId": "e43dceda-64f7-4414-ee26-b6ea4c193e40"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"datasets\",\n  \"rows\": 47,\n  \"fields\": [\n    {\n      \"column\": \"audio_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"a274f473-e190-4a49-ad40-869298519654\",\n          \"9fbcfab5-b7f3-49f6-87bf-46dc294884f6\",\n          \"21d5b5a0-236a-4b9a-b4e8-aa75cdbb14d6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"data/non-medical/df50b219-f5aa-4d56-9f33-6865c96fda2b_0c80966970ec5877368cab246f1ee2b7_EOKmZ6h8.wav\",\n          \"data/non-medical/185152d7-0c16-45e5-8f1e-862e5766f39a_278ff438c4cfec175028c571db4ed815_36K3TRQt.wav\",\n          \"data/non-medical/60344b07-b93e-4e14-8b1b-d544d9cd6a16_c6100bbfbf76d7c7900b850092205437_UpyTnj39.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"00:00:50\\r\\n[Speaker 1]: My name is Favour, and I consent to recording this conversation.\\r\\n00:03:47\\r\\n\\r\\n00:03:56\\r\\n[Speaker 2]: My name is Precious, and I consent to recording this conversation.\\r\\n00:06:42\\r\\n\\r\\n00:06:59\\r\\n[Speaker 1]: Okay, so we'll be looking at heart diseases, and by way of introduction, we see that heart disease, also known as cardiovascular disease, refers to a range of conditions that affect the heart and its functions. These include coronary artery disease, heart failure, arrhythmias, and congenital heart defects, among others. Now, do you have anything to say about that?\\r\\n00:29:34\\r\\n\\r\\n00:30:05\\r\\n[Speaker 2]: Okay. Heart disease is recently one of the sudden causes of death in our environment. And like you said, it ranges from diseases like myocardial infarction, congestive cardiac failure, hypertension, congenital defects as well, and usually a compendium of diseases that affect the heart and the blood vessels and have a ripple effect in the environment.\\r\\n00:52:13\\r\\n\\r\\n00:52:38\\r\\n[Speaker 1]: Okay, true. Okay. So, going further, I would like to go into have an overview, rather, of some symptoms of heart diseases. And we see that symptoms can vary depending on the specific heart condition. But some common symptoms now could include chest pain, which is also known as angina, shortness of breath, fatigue or weakness, palpitations that's irregular or fast heartbeats, swelling in the legs, ankles and feet, dizziness or lightheadedness, nausea or indigestion. Do you have anything further to say about this?\\r\\n01:27:19\\r\\n\\r\\n01:27:27\\r\\n[Speaker 2]: Okay, so, for the symptoms you just mentioned, it varies according to the heart condition. So, in some heart conditions, like congestive cardiac failure, you can see shortness of breath, also known as dyspnoea, where the individual finds it difficult to breathe in. And usually when there's the heart condition, it has an effect on the lungs and leads to pulmonary edema, where it obstructs and blocks the alveoli, so making breathing difficult. Also, the individual can notice fatigue or weakness and inability to do certain activities compared to before. Usually he will be able to run certain distances, but he will not be able to anymore. Those are also symptoms of cardiac diseases. Also, chest pain, like you mentioned, angina pectoris, where there's pain around the region of the chest can also be a presentation of cardiovascular diseases. Palpitations, which is irregular or fast heartbeats, can also present as heart, as cardiac conditions, you can have edema, which is what you know as swelling in the legs, where the person's leg, ankle, or feet can be swollen, it can be pitting or non-pitting edema. Also, nausea, vomiting, indigestion and dizziness, so to mention, but a few. These are some of the risks, and these are some of the symptoms of cardiovascular diseases.\\r\\n02:48:09\\r\\n\\r\\n02:48:18\\r\\n[Speaker 1]: Yeah. Alright. So, talking about risk factors for heart diseases, we see that they can be divided into modifiable and non-modifiable factors. Now, let's go into modifiable factors. We have high blood pressure, which is hypertension, high cholesterol levels, smoking, diabetes, overweight or obesity, physical inactivity, unhealthy diet, excessive alcohol consumption, stress and poor mental health, and a whole lot of others. And then going into non-modifiable, we see age, we see family, we see gender, we see ethnicity. So, do you have anything about modifiable risk factors?\\r\\n03:34:43\\r\\n\\r\\n03:35:43\\r\\n[Speaker 2]: Okay, for the modifiable risk factors, these are risk factors that change can be, can be affected.\\r\\n03:45:02\\r\\n\\r\\n03:45:37\\r\\n[Speaker 1]: Yes.\\r\\n03:45:53\\r\\n\\r\\n03:46:02\\r\\n[Speaker 2]: So, these risk factors are not, are not genetic, they are not inbuilt, you can do something about them. So, for example, smoking. So, smoking poses a very, very high-risk cardiovascular diseases. An individual who smokes is at risk of different cardiovascular diseases, like atherosclerosis, that will eventually lead to hypertension, that will lead to congestive cardiac failure. So, obesity is another risk factor. An individual who is overweight beyond normal for his age and weight is going to tend towards having cardiovascular complications. So also, someone who has a sedentary lifestyle, who has less of physical activity, who usually doesn't do much, can also pose a risk for cardiovascular disease. Someone who does not exercise, someone who consumes unhealthy diets, that consumes a lot of fully unsaturated fats, is also at risk of cardiovascular diseases. Someone with high cholesterol levels, too much intake of alcohol and stress, to mention but a few. All of these are modifiable risk factors for cardiovascular diseases.\\r\\n04:53:15\\r\\n\\r\\n04:53:29\\r\\n[Speaker 1]: Okay, and how about the non-modifiable.\\r\\n04:56:27\\r\\n\\r\\n04:56:36\\r\\n[Speaker 2]: Okay, for the non-modifiable risk factors. These risk factors, generally, these risk factors are in the individual and, for example, age. An individual who is older has a risk for more cardiovascular diseases because with age, the blood vessels become harder, there's thickening, there's fibrosis. This can predispose one to hypertension and subsequent cardiovascular disease. Also, a person who has a positive family history for a heart disease can also have a heart disease. For example, the father had myocardial infraction. He or she can also have myocardial infarction. For gender, usually men have a higher risk for cardiovascular diseases than female, and for some races, they are also predisposed to cardiovascular diseases.\\r\\n05:45:19\\r\\n\\r\\n05:45:28\\r\\n[Speaker 1]: Alright, that's very, very true. So, let's talk about the prevention of heart diseases. So, we see that preventing heart disease now involves managing risk factors and making healthy lifestyle choices. So, talking about healthy diets, we see that person should consume a diet rich in fruits, vegetables, whole grains, lean proteins, and healthy fats and should also limit intake of saturated fats, trans fats, cholesterol, sodium and added sugar. And we also see in the aspect of stress, managing stress. A person should practice relaxation techniques such as meditation, yoga or deep breathing exercises. We also see regular health checks, checkups. Monitor your blood pressure consistently, cholesterol also and blood sugar levels regularly. Follow medical advice and take prescribed medications as directed. We also see avoid smoking and limit alcohol. Now, do you have anything to say about smoking? Like avoiding smoking and limiting alcohol?\\r\\n06:56:52\\r\\n\\r\\n06:57:40\\r\\n[Speaker 2]: Okay. Yes. Yes. That is very, very, very important. That is very, very, very important. So, there's almost no benefit of smoking? Yes, smoking should be avoided, limit your alcohol intake, manage stress, go for regular health checkups to check your blood pressure and be sure that you are on track. And do make sure you stay hydrated, maintain a healthy body weight, get enough sleep, get enough rest as well.\\r\\n07:32:04\\r\\n\\r\\n07:32:24\\r\\n[Speaker 1]: Yeah, that's true. Okay, so now i'll want to ask a question. So, what are some lifestyle changes that you have made to lower your risk of developing heart disease?\\r\\n07:44:16\\r\\n\\r\\n07:44:36\\r\\n[Speaker 2]: Okay, so for lifestyle changes, things like exercise, exercising regularly and as often as possible. Yes. Also, good diets, healthy diets, reducing the level of junk and taking more fruits and vegetables can help to reduce the risk of cardiovascular diseases. Good rest, avoiding alcohol intake and smoking can also reduce the risk of cardiovascular diseases.\\r\\n08:04:52\\r\\n\\r\\n08:13:08\\r\\n[Speaker 1]: All true. Thank you so much.\\r\\n08:15:09\\r\\n\\r\\n08:16:46\\r\\n[Speaker 2]: Thank you.\\r\\n08:17:59\",\n          \"\\r\\n00:02:28\\r\\n[Speaker 1]: Alright. My name is Mpomufu gang and I give consent to recording this conversation.\\r\\n\\r\\n00:09:06\\r\\n[Speaker 2]: My name is Saufugeng and I give consent to recording this conversation.\\r\\n\\r\\n00:13:25\\r\\n[Speaker 1]: Alright, so our topic for today is technology.\\r\\n\\r\\n00:19:46\\r\\n[Speaker 2]: Does it bring people together? Does it bring people closer or does it drive them? Apartheid? What's your take on that?\\r\\n\\r\\n00:28:55\\r\\n[Speaker 1]: This is a very tricky one because in my opinion, technology bring people together and it also drives them apart. But in this instance, I would say that it's bringing people together.\\r\\n\\r\\n00:43:50\\r\\n[Speaker 2]: I disagree. The majority of the technology, mostly it like drives people apart.\\r\\n\\r\\n00:55:54\\r\\n[Speaker 1]: You think so?\\r\\n\\r\\n00:57:54\\r\\n[Speaker 2]: Yes.\\r\\n\\r\\n00:57:54\\r\\n[Speaker 1]: All right, so the main reason that I'm saying that it's bringing people closer.\\r\\n\\r\\n01:04:38\\r\\n[Speaker 2]: Would be.\\r\\n\\r\\n01:08:03\\r\\n[Speaker 1]: The source of communication. Right? So we are able to communicate with our loved ones, even though they are across borders, they are in other countries, they are not close to us, but we are able to get in touch with them. And it's because of technology that is possible, you know? So why would you think that it's driving people apart?\\r\\n\\r\\n01:40:45\\r\\n[Speaker 2]: It goes both ways, actually.\\r\\n\\r\\n01:42:48\\r\\n[Speaker 1]: It does.\\r\\n\\r\\n01:45:01\\r\\n[Speaker 2]: But the majority, I would say, drives people apart because, like, there's a lot of negativity in social media.\\r\\n\\r\\n01:53:03\\r\\n[Speaker 1]: Yeah, because social media is also a part of technology.\\r\\n\\r\\n01:59:50\\r\\n[Speaker 2]: It drives people apart because, like, example, if you post something and like, people are good in your comment and violate you, say bad things about you, bully you. Cyberbullying just because. Yeah, cyberbullying. And it will get you like self esteem down.\\r\\n\\r\\n02:18:07\\r\\n[Speaker 1]: Yeah.\\r\\n\\r\\n02:23:27\\r\\n[Speaker 2]: And for people, you know, like, like personally, you would like, they would like sometimes like expose you for things that shouldn't be known. And most of the times you would like, cut those people off. That's why it's driving them apart.\\r\\n\\r\\n02:46:53\\r\\n[Speaker 1]: That's why. Yeah, you, you have a point there. You know, the other day I was actually, I saw this post on Facebook. Right?\\r\\n\\r\\n02:56:32\\r\\n[Speaker 2]: Yes.\\r\\n\\r\\n02:56:32\\r\\n[Speaker 1]: So there was this, there was a Snapchat of this lady and a guy. So they were holding hands in the mall, you know, but the caption was like, you know what? This guy is a married man, so he was actually cheating on his wife. You know, so it's actually a bad impact because, all right. It is a good thing that a woman finally knows the wife found out.\\r\\n\\r\\n03:30:14\\r\\n[Speaker 2]: And knows the truth.\\r\\n\\r\\n03:30:14\\r\\n[Speaker 1]: Yeah. What her husband was actually up to all this time. But the thing is, it's going to hurt her. She's going to hurt to.\\r\\n\\r\\n03:40:17\\r\\n[Speaker 2]: That's why I say it's driving them apart.\\r\\n\\r\\n03:42:50\\r\\n[Speaker 1]: Yes. And in a case of children, social.\\r\\n\\r\\n03:45:20\\r\\n[Speaker 2]: Media, you know, they will get bullied.\\r\\n\\r\\n03:48:37\\r\\n[Speaker 1]: You know, when once something is actually there on social media, it is there forever. Forever. If you go after 15 years and search for it still there, you're going to find it, you know? But then I heard that if you want to take something down on social media or on a website, it cost you a lot of cash. Have you heard of them?\\r\\n\\r\\n04:09:13\\r\\n[Speaker 2]: Even if you do take it down, people who know.\\r\\n\\r\\n04:14:02\\r\\n[Speaker 1]: Yeah.\\r\\n\\r\\n04:14:02\\r\\n[Speaker 2]: Will, like, bully you. They still know. That doesn't mean when it. When the video or anything, it's taken. It's taken. It's taken down on the. Yeah, social media, it's not taken down on people's, like, brains. They remember it.\\r\\n\\r\\n04:32:02\\r\\n[Speaker 1]: Google is actually spying on us. I'm telling you. I'm telling you. So I also feel sorry for the kids, you know, to. Because they're gonna get bullied at school and, yeah, it's driving them apart in some way, you know. So in a case of schools, would you say that technology has brought people together or driven them apartheid schools premises?\\r\\n\\r\\n05:03:33\\r\\n[Speaker 2]: I don't know about that, because, like, in our school, we don't use. Actually, we don't use phones.\\r\\n\\r\\n05:08:46\\r\\n[Speaker 1]: Yeah.\\r\\n\\r\\n05:08:46\\r\\n[Speaker 2]: Yeah. So, yeah, we only use books, but for other, like, schools where they use, like, technology, like laptops, it's. It's, it's. It's a good thing because, like, the books are heavy. Books are heavy. So having to carry, like, um, just laptop and it has all the textbooks you need to have is actually a good thing. It's a good thing, yeah.\\r\\n\\r\\n05:39:10\\r\\n[Speaker 1]: All right, so in the ongoing debate about the impact of technology on human relationships, the questions arises. You know, this question, this topic that we actually talking about, it arises. Lot of time, you know, I've been hearing it about. I've been hearing about it for the longest time. So I also feel that it brings us together because I can actually work from home, you know, with my laptop, not being there by the office. I can talk to my colleagues and interact with them and also with clients, you know, if I need to talk with them regarding our work and stuff.\\r\\n\\r\\n06:29:52\\r\\n[Speaker 2]: And technology is addictive, so it drives people, um, drives people away, like, they don't from themselves mental states and friends, because, like, most. Most people would rather, like, go. Go on their phone and scroll on TikTok, social media, score anything, and not go with their friends and, like, having, like, you know.\\r\\n\\r\\n06:55:19\\r\\n[Speaker 1]: Yeah. So, like, in this case, we didn't actually disagree with each other that much. We actually agree with each other because it goes both ways, you know? So I would say that it has the capacity to both bring people close together and create distance, depending on how it is utilized.\\r\\n\\r\\n07:20:19\\r\\n[Speaker 2]: Utilized.\\r\\n\\r\\n07:20:19\\r\\n[Speaker 1]: You know, by leveraging digital tools, you know, thoughtfully and managing screen time and in person interactions, you know, people can.\\r\\n\\r\\n07:35:37\\r\\n[Speaker 2]: Benefit from technology, can harness the benefits.\\r\\n\\r\\n07:38:38\\r\\n[Speaker 1]: Yeah, they can. While preserving the richness of personal connections. We actually shouldn't forget that we actually need each other more than we need technology know. But it's also, it's, it's actually always nice to go paperless. As you said, books are heavy. And, you know, what I like about computers, or rather laptops is that you can create your file, you can create your file and your documents and you can file your documents nicely in your, in your folders, in your computer, alphabetically. So whenever you need documents. Yes. It's easier, it's easier to go there.\\r\\n\\r\\n08:27:50\\r\\n[Speaker 2]: Than carrying loads of weight.\\r\\n\\r\\n08:30:45\\r\\n[Speaker 1]: Yeah. Yes. So other than that, I feel that we, and, you know, and white light.\\r\\n\\r\\n08:39:08\\r\\n[Speaker 2]: We need lightest technology.\\r\\n\\r\\n08:41:36\\r\\n[Speaker 1]: Yeah, lightest technology.\\r\\n\\r\\n08:43:27\\r\\n[Speaker 2]: Light bulbs.\\r\\n\\r\\n08:43:27\\r\\n[Speaker 1]: Yeah, yeah. To cook, we need technology. Yeah.\\r\\n\\r\\n08:48:18\\r\\n[Speaker 2]: We need stoves. You know, so it actually has a good, like, it goes both sides.\\r\\n\\r\\n08:54:30\\r\\n[Speaker 1]: Yeah. But when coming to a point of machinery innovation, I feel that most people.\\r\\n\\r\\n09:05:39\\r\\n[Speaker 2]: Loses their job because of their job, because of technology. Yeah, yeah. Though, um, technology actually that advances and they make robots so they cannot pay like, people.\\r\\n\\r\\n09:21:59\\r\\n[Speaker 1]: They cannot pay people.\\r\\n\\r\\n09:21:59\\r\\n[Speaker 2]: And, uh, the robots are actually most efficient and give out better results.\\r\\n\\r\\n09:29:17\\r\\n[Speaker 1]: But it's not, it's, yeah, not a.\\r\\n\\r\\n09:32:02\\r\\n[Speaker 2]: Good thing on, like, for the companies. A good, it's a good thing because, like, they don't get delayed because of people. Because some people can have a limit of, like, physical labor.\\r\\n\\r\\n09:45:02\\r\\n[Speaker 1]: Yeah.\\r\\n\\r\\n09:45:02\\r\\n[Speaker 2]: So, like, the world do not get, like, don't have like, day off day.\\r\\n\\r\\n09:52:02\\r\\n[Speaker 1]: I do get that it's an ongoing thing, productivity. But then when it, when it comes, yeah, when it comes to maybe do they service robots, those robots or whatever, how do they, like, do they maintain them? Maintenance, my guy. Like, I feel that they, they do need maintenance because you can't, you can't, you can't work every day without maintenance. You know, it's like a car. You need to service your car after a certain time of, period of time. Yes. You need to service it. You need to service like, everything. Even your laptop, your computer, you, laptop, you, you need to service them. Yeah. So I don't know. But then, you know what? I'll research about that if robots are actually being maintained or what. So in concluding everything, I feel that today's topic was very educative to me. Yeah, it was very educative to me because we actually don't, we actually take things, like, for granted. For granted. But I also feel that, you know, what? What do you feel about google?\\r\\n\\r\\n11:09:04\\r\\n[Speaker 2]: Google? I feel. I feel like it's a good thing.\\r\\n\\r\\n11:11:45\\r\\n[Speaker 1]: Yeah.\\r\\n\\r\\n11:11:45\\r\\n[Speaker 2]: It has this downside. Downside body. But mostly. Mostly it's a good thing because, like, you could just google something if, like, you need something, like, work related. Just go to google quick search, get what you want.\\r\\n\\r\\n11:27:52\\r\\n[Speaker 1]: Or maybe if you're busy with a.\\r\\n\\r\\n11:29:18\\r\\n[Speaker 2]: Rather than. Rather than going to a book, reading everything. Yeah. Going to libraries, you have Google fast. Yeah.\\r\\n\\r\\n11:37:46\\r\\n[Speaker 1]: Or maybe when you. Maybe when you're busy with your book and then you come across this road that you really do not understand, so you kind of.\\r\\n\\r\\n11:46:10\\r\\n[Speaker 2]: It's just quick to go to Google rather than to fetch a dictionary and go search for the word. I feel like a lot of.\\r\\n\\r\\n12:00:09\\r\\n[Speaker 1]: Yeah. Some people may not feel the same way that we do, but I feel that, you know, and there are a lot of things that, you know, we can teach our toddlers. There are a lot of videos that we get on phones, social media about, you know, learning them side words, learning them, the sounds of. Of every Alphabet and stuff, making it creative, you know? So I think that it is a. It is bringing people together because, I mean, do you watch cocomelon? Yeah. Because immediately, when your toddlers acting upon you, you immediately turn on the cocomelo on your smart tv. It's actually technology. And then he or she becomes pleasant, happy with you and stuff. So it brought you together, and they become smart.\\r\\n\\r\\n13:05:47\\r\\n[Speaker 2]: Those shows, like, give. Give out education.\\r\\n\\r\\n13:10:54\\r\\n[Speaker 1]: Yeah. But then I also heard that we should actually choose which shows should they watch.\\r\\n\\r\\n13:15:35\\r\\n[Speaker 2]: Yeah, because there are some. That's what I'm saying. There are some good things. There's some bad things. There's some, like, kid things you don't know that, like, um, has a better gender.\\r\\n\\r\\n13:27:53\\r\\n[Speaker 1]: Yeah.\\r\\n\\r\\n13:27:53\\r\\n[Speaker 2]: Like, your kids. So your kids are not gonna grow up. Like, how. They're actually gonna actually have to.\\r\\n\\r\\n13:34:36\\r\\n[Speaker 1]: Yes.\\r\\n\\r\\n13:34:36\\r\\n[Speaker 2]: But the good side is they know. They. They get to know a lot of things. They get to know how to, like, talk to people because, like, they remember. Oh, I remember this. I remember this. So, yeah, technology is a. I once saw this.\\r\\n\\r\\n13:51:39\\r\\n[Speaker 1]: This video on TikTok. This guy was actually trashing Peppa pig. Do you know Peppa pig? Yes, peppa pig. He was actually trashing it, saying that we shouldn't let kids watch Peppa Pig because she's actually rude and she's so controlling, you know? And then one time, I took time to actually watch it because my son watches it. He loves it. Yes. So I actually took time to watch it, right? So while I was busy watching it, what he said and comparing to what I see to what I saw at that moment was actually two different things. You know, I saw pepper conducting good manners for his. For her brother George, you know?\\r\\n\\r\\n14:50:53\\r\\n[Speaker 2]: Now let's wrap it up. In conclusion, technology has good and bad things, so you just gotta drive them.\\r\\n\\r\\n14:59:15\\r\\n[Speaker 1]: Apartheid.\\r\\n\",\n          \"00:00:28\\r\\n[Speaker 1]: My name is Ovoba. I consent to recording this conversation.\\r\\n00:05:33\\r\\n\\r\\n00:05:54\\r\\n[Speaker 2]: My name is Victor. I consent to recording this conversation.\\r\\n00:08:57\\r\\n\\r\\n00:10:00\\r\\n[Speaker 1]: Right, Victor? You're welcome. Today we'll be talking about something that is popular, that is cut across almost all the cultures. Something that a lot of people know about. And many people always look forward to it. Victor, can you guess?\\r\\n00:30:32\\r\\n\\r\\n00:31:30\\r\\n[Speaker 2]: I can't guess.\\r\\n00:31:57\\r\\n\\r\\n00:32:23\\r\\n[Speaker 1]: Okay.\\r\\n00:32:43\\r\\n\\r\\n00:32:52\\r\\n[Speaker 2]: Is it birthday?\\r\\n00:33:32\\r\\n\\r\\n00:34:37\\r\\n[Speaker 1]: Exactly. Victor will be talking about birthday today. So I know that everybody alive has a birthday. But this time around, I don't know if everybody alive really does the birthday celebration type of thing. So, Victor, can I know what you think of birthday? What do you understand as birthday? Or what's? What's your simple explanation or definition of a birthday?\\r\\n01:04:33\\r\\n\\r\\n01:05:51\\r\\n[Speaker 2]: Birthday, in the simplest definition, is a special day set apart to remember the day you were born. And its mostly held on the month and the dates that you were giving birth to. Your official date of birth.\\r\\n01:21:33\\r\\n\\r\\n01:22:11\\r\\n[Speaker 1]: Okay, so birthday is something that people. celebrate every year right? To remember the other year or the other, other, other year that they were giving birth to.\\r\\n01:34:09\\r\\n\\r\\n01:34:10\\r\\n[Speaker 2]: Yeah.\\r\\n01:34:25\\r\\n\\r\\n01:35:03\\r\\n[Speaker 1]: Okay and its celebrated the same day and month. Okay, so, Victor, this birthday celebration, I learned that its for only rich people, that poor people don't celebrate birthday. Do you think that is true?\\r\\n01:51:21\\r\\n\\r\\n01:52:07\\r\\n[Speaker 2]: Poor people don't celebrate birthday. Actually, actually its subjective, because some rich people don't like celebrating their birthday.\\r\\n02:04:32\\r\\n\\r\\n02:05:25\\r\\n[Speaker 1]: Okay.\\r\\n02:05:45\\r\\n\\r\\n02:06:08\\r\\n[Speaker 2]: But I'll not remove the fact that to celebrate your birthday, you actually need money. So, some people, because of their poor, they have many problems in their lives, so birthday is the least of their worries. So, the highest they can get on their birthday is just a happy birthday. But most times they just even forget their birthday because they're going through a lot. So birthday is the last thing on their mind.\\r\\n02:31:05\\r\\n\\r\\n02:32:30\\r\\n[Speaker 1]: So what you're saying is that a lot of people don't remember to really celebrate \\r\\ntheir birthday probably because of what they are facing.\\r\\n02:41:19\\r\\n\\r\\n02:41:39\\r\\n[Speaker 2]: Yes.\\r\\n02:42:59\\r\\n\\r\\n02:42:20\\r\\n[Speaker 1]: Okay, Victor, can I know when last you celebrated your birthday?\\r\\n02:48:33\\r\\n\\r\\n02:49:53\\r\\n[Speaker 2]: Just a few months ago.\\r\\n02:50:52\\r\\n\\r\\n02:51:02\\r\\n[Speaker 1]: Few months ago?\\r\\n02:52:59\\r\\n\\r\\n02:52:09\\r\\n[Speaker 2]: Yes.\\r\\n02:52:25\\r\\n\\r\\n02:52:45\\r\\n[Speaker 1]: Okay, so that few months ago, did you really remember that it was your birthday or someone reminded you?\\r\\n02:58:42\\r\\n\\r\\n02:58:43\\r\\n[Speaker 2]: No, I remembered. I remembered. But obviously, sometimes I used to forget it's my birthday. Like, the previous year, I forgot it was my birthday. My birthday passed. Like, can you imagine, like, for somebody to forget the day they were born. Like, I didn't put too much value into birthday, because I felt birthday is just an ordinary day like, it's just. So if I should be sadistic, some people do view birthdays as one year closer to your death. So to them its not something special. Just another day, just a day they were born. Nothing much. Nothing. Nothing to see there.\\r\\n03:38:34\\r\\n\\r\\n03:40:23\\r\\n[Speaker 1]: Alright. So you, few months ago, you celebrated your birthday. Can I know, Victor, if there is any of those, your birthdays that you find very, very special or the one that had some events that made you, it very memorable for you. That you can say, I can't forget my second two years old birthday, three years old birthday or any of those.\\r\\n04:05:09\\r\\n\\r\\n04:05:15\\r\\n[Speaker 2]: I can't actually remember the year or the age I was in but I'll not call it my personal birthday. Because on my personal birthday, the highest they did for me, was happy birthday and it ends there. Nothing special. Maybe my mom bought chicken that day and we cooked it, just a remembrance of me and ended there. No special events, no special stuff happened but something later happened. Because few weeks after that, my parents decided to do a general birthday to celebrate everybody in our house. So we did it in a large way. My parents invited people to our house, our compound. We celebrated all our birthdays in one day. I know it's funny it's funny yeah. It does not normally happen in some families.\\r\\n04:58:39\\r\\n\\r\\n04:58:39\\r\\n[Speaker 1]: Family of Victor Demas.\\r\\n05:00:14\\r\\n\\r\\n05:00:15\\r\\n[Speaker 2]: It does not happen in some families but my father had to do it and that day, something special happened. My father did us a special surprise. He bought us really expensive, table tennis board where we can use and play table tennis. So up to date, that table tennis is still there. So, I think that was the most memorable birthday celebration. Even though it was not my birthday. It was a family birthday. It was the most memorable. Something close to a memory birthday I had.\\r\\n05:35:22\\r\\n\\r\\n05:36:28\\r\\n[Speaker 1]: So say the one that you people had generally as a family was your most memorable birthday. Wow. So outside that, your normal birthday, what, don't you think about, cake? Because, I learned that, I see that most people, they see birthday as a day that they have to purchase cake or eat cake or I, share cakes to their friends. Do you think that without cake there will be no birthday or something? Birthday celebration. Do you think that cake is extremely necessary for birthday? That people cannot celebrate birthday without cake?\\r\\n06:28:48\\r\\n\\r\\n06:32:15\\r\\n[Speaker 2]: Birthday is a symbol of, sorry, cake is a symbol of birthdays. Like, it's something attached to birthdays. Like, literally, if you see a cake with candles in a picture, obviously, you know, it was, its used to remember somebody's birthday. It signifies birthday. Just like, chicken, like turkey, represents Easter, thanksgivings.\\r\\n06:58:06\\r\\n\\r\\n06:58:34\\r\\n[Speaker 1]: Yeah.\\r\\n06:58:50\\r\\n\\r\\n06:59:25\\r\\n[Speaker 2]: Same way with bunnies represents Easter thanksgiving. Rice, rice and stew represent Sundays.\\r\\n07:08:07\\r\\n\\r\\n07:09:54\\r\\n[Speaker 1]: That's Nigeria only.\\r\\n07:10:09\\r\\n\\r\\n07:10:17\\r\\n[Speaker 2]: Nigeria only. So cake represent birthdays. It's, it's, I don't know where the tradition started, but it has been there for a long time.\\r\\n07:18:55\\r\\n\\r\\n07:18:12\\r\\n[Speaker 1]: Do you think it's Nigerian tradition or it's foreign?\\r\\n07:21:58\\r\\n\\r\\n07:21:19\\r\\n[Speaker 2]: Should be foreign because our old fathers never knew what cake was.\\r\\n07:25:42\\r\\n\\r\\n07:26:02\\r\\n[Speaker 1]: Okay, so how do you think that your old father celebrated their birthday? Or they don't celebrate birthday?\\r\\n07:33:20\\r\\n\\r\\n07:33:38\\r\\n[Speaker 2]: I don't think they celebrated their birthday.\\r\\n07:34:52\\r\\n\\r\\n07:34:53\\r\\n[Speaker 1]: So what you're saying that birthday is not a tradition of your ancestral home?\\r\\n07:39:02\\r\\n\\r\\n07:39:10\\r\\n[Speaker 2]: Because if you ask some of these, our great grandfathers and our grandfathers that are still alive, some people are lucky to have their grandfathers. That's, that's actually good. So, but if you ask them, most of them don't know their age.\\r\\n07:51:18\\r\\n\\r\\n07:51:48\\r\\n[Speaker 1]: Okay.\\r\\n07:52:16\\r\\n\\r\\n07:52:22[Speaker 2]: They don't know their age and that just tells you that they don't keep track of their age and if they don't keep the track of age, obviously they were not celebrating their birthday. They were not being reminded that this was the day they were born. Because if they were remembering this, was the day they're born, they will not, they will actually remember the dates they were born and they will be able to calculate their age.\\r\\n08:10:06\\r\\n\\r\\n08:10:07\\r\\n[Speaker 1]: So they don't really put much emphasis in birthday, then. Wow, the old people really missed a lot. So old people, I think that's true, actually, because I barely remember that when my grandmother died, we had to guess her age by estimate. It wasn't really her exact age that was written on the poster. So we have to go through her age mates to discover maybe the age, her age.\\r\\n08:41:40\\r\\n\\r\\n08:42:25\\r\\n[Speaker 2]: Yeah.\\r\\n08:42:49\\r\\n\\r\\n08:44:00\\r\\n[Speaker 1]: So if you have kids, would you like to introduce them to birthday celebration?\\r\\n08:49:26\\r\\n\\r\\n08:51:07\\r\\n[Speaker 2]: If I have kids, obviously.\\r\\n08:52:34\\r\\n\\r\\n08:52:47\\r\\n[Speaker 1]: Are you, will you celebrate them just normal, happy birthday, like you were raised.\\r\\n08:59:20\\r\\n\\r\\n09:00:34\\r\\n[Speaker 2]: To have a limit for the first few years of their life, I'll be celebrating a birthday, but, as they grow older, I think I'll dial down on the way I celebrate their birthday. You can just be happy, wish then and maybe send them money. If I'm capable, I'll be sending them money. Happy birthday, take this as your birthday gift, that kind of thing. But not to come and do a ceremony to celebrate a birthday. But it's very essential you do a ceremonious birthday for your kids in their first few years of life. Maybe their first birthday, second birthday, fifth birthday, 6th birthday. But as a grow older, the birthday ceremonies thing, you can dial it down the beach and just do like a small gifting to them just to remind them that you love them and make them feel special on their birthday.\\r\\n09:47:27\\r\\n\\r\\n09:47:50\\r\\n[Speaker 1]: Okay? So what you're saying is that those early age of their life where they take pictures and all that, that is very necessary that you celebrate their birthday for them, at least for the sake of memory. Alright, Victor, I appreciate your input on this issue of birthday. So I believe to see you around again for more discussion. Thank you so much, Victor.\\r\\n10:15:27\\r\\n\\r\\n10:16:08\\r\\n[Speaker 2]: Yeah, thank you very much.\\r\\n10:17:13\\r\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"26-40\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Urhobo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"OSCE-Doctor-Patient\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"NG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 255.89710748882177,\n        \"min\": 138.554989,\n        \"max\": 1205.075986,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          497.214989\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "datasets"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-463c80d9-61c9-4114-b6f4-07f747b823eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_id</th>\n",
              "      <th>path</th>\n",
              "      <th>transcript</th>\n",
              "      <th>age_group</th>\n",
              "      <th>gender</th>\n",
              "      <th>accent</th>\n",
              "      <th>domain</th>\n",
              "      <th>country</th>\n",
              "      <th>audio_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58efe9ef-6c76-4d17-b1b2-f397552a0c0e</td>\n",
              "      <td>data/medical/95aed576-a1d6-42f3-9651-7103e0717...</td>\n",
              "      <td>00:01:13\\r\\n[Speaker 1]: Good day. I am Doctor...</td>\n",
              "      <td>26-40</td>\n",
              "      <td>Female</td>\n",
              "      <td>Urhobo</td>\n",
              "      <td>OSCE-Doctor-Patient</td>\n",
              "      <td>NG</td>\n",
              "      <td>213.635986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bbc98b6e-f165-4475-b0b3-8e25ab259323</td>\n",
              "      <td>data/medical/9d838ece-8db5-4736-96d8-581071bd5...</td>\n",
              "      <td>\\r\\n00:01:25\\r\\n[Speaker 1]: Hello, how are yo...</td>\n",
              "      <td>26-40</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>OSCE-Doctor-Patient</td>\n",
              "      <td>NG</td>\n",
              "      <td>216.760998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d3550502-5ae7-4314-8a21-036d488cd8d6</td>\n",
              "      <td>data/medical/656c42a7-6faa-4486-979f-6f64769bd...</td>\n",
              "      <td>\\r\\n00:00:59\\r\\n[Speaker 1]: Hello. I am docto...</td>\n",
              "      <td>26-40</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>OSCE-Doctor-Patient</td>\n",
              "      <td>NG</td>\n",
              "      <td>218.482993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b6f48ed7-e629-4e50-af63-1c9067c34ef2</td>\n",
              "      <td>data/medical/cd255fe0-ebc2-47a0-a990-2ab1ba9ca...</td>\n",
              "      <td>00:00:35\\r\\n[Speaker 1]: Hello, how are you?\\r...</td>\n",
              "      <td>26-40</td>\n",
              "      <td>Female</td>\n",
              "      <td>Urhobo</td>\n",
              "      <td>OSCE-Doctor-Patient</td>\n",
              "      <td>NG</td>\n",
              "      <td>220.120998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f9bd30b2-684d-470e-b65c-ced156da0bbb</td>\n",
              "      <td>data/medical/304d6402-91d8-4a4f-8a65-143a7c767...</td>\n",
              "      <td>\\r\\n\\r\\n00:04:08\\r\\n[Speaker 1]: Hi, I am Dr. ...</td>\n",
              "      <td>26-40</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yoruba</td>\n",
              "      <td>OSCE-Doctor-Patient</td>\n",
              "      <td>NG</td>\n",
              "      <td>235.932993</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-463c80d9-61c9-4114-b6f4-07f747b823eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-463c80d9-61c9-4114-b6f4-07f747b823eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-463c80d9-61c9-4114-b6f4-07f747b823eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0d7ef6f2-511e-4e7c-823f-d1b9f225c7b1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d7ef6f2-511e-4e7c-823f-d1b9f225c7b1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0d7ef6f2-511e-4e7c-823f-d1b9f225c7b1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                               audio_id  \\\n",
              "0  58efe9ef-6c76-4d17-b1b2-f397552a0c0e   \n",
              "1  bbc98b6e-f165-4475-b0b3-8e25ab259323   \n",
              "2  d3550502-5ae7-4314-8a21-036d488cd8d6   \n",
              "3  b6f48ed7-e629-4e50-af63-1c9067c34ef2   \n",
              "4  f9bd30b2-684d-470e-b65c-ced156da0bbb   \n",
              "\n",
              "                                                path  \\\n",
              "0  data/medical/95aed576-a1d6-42f3-9651-7103e0717...   \n",
              "1  data/medical/9d838ece-8db5-4736-96d8-581071bd5...   \n",
              "2  data/medical/656c42a7-6faa-4486-979f-6f64769bd...   \n",
              "3  data/medical/cd255fe0-ebc2-47a0-a990-2ab1ba9ca...   \n",
              "4  data/medical/304d6402-91d8-4a4f-8a65-143a7c767...   \n",
              "\n",
              "                                          transcript age_group  gender  \\\n",
              "0  00:01:13\\r\\n[Speaker 1]: Good day. I am Doctor...     26-40  Female   \n",
              "1  \\r\\n00:01:25\\r\\n[Speaker 1]: Hello, how are yo...     26-40  Female   \n",
              "2  \\r\\n00:00:59\\r\\n[Speaker 1]: Hello. I am docto...     26-40  Female   \n",
              "3  00:00:35\\r\\n[Speaker 1]: Hello, how are you?\\r...     26-40  Female   \n",
              "4  \\r\\n\\r\\n00:04:08\\r\\n[Speaker 1]: Hi, I am Dr. ...     26-40  Female   \n",
              "\n",
              "   accent               domain country  audio_duration  \n",
              "0  Urhobo  OSCE-Doctor-Patient      NG      213.635986  \n",
              "1  Yoruba  OSCE-Doctor-Patient      NG      216.760998  \n",
              "2  Yoruba  OSCE-Doctor-Patient      NG      218.482993  \n",
              "3  Urhobo  OSCE-Doctor-Patient      NG      220.120998  \n",
              "4  Yoruba  OSCE-Doctor-Patient      NG      235.932993  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU8hBeo-o1i1"
      },
      "outputs": [],
      "source": [
        "def merge_consecutive_segments(predicted_segments):\n",
        "  merged_segments = []\n",
        "  last_start, last_end, last_speaker = None, None, None\n",
        "\n",
        "  # predicted_segments is a list of lists of strings, e.g., [['0.000 1.840 speaker_0', ...]]\n",
        "  # We need to iterate through the inner list of segments\n",
        "  if predicted_segments and isinstance(predicted_segments[0], list):\n",
        "    segments_list = predicted_segments[0]\n",
        "  else:\n",
        "    # Handle unexpected format or empty list\n",
        "    return []\n",
        "\n",
        "  for segment_str in segments_list:\n",
        "    try:\n",
        "        start_str, end_str, speaker = segment_str.split()\n",
        "        start_time = float(start_str)\n",
        "        end_time = float(end_str)\n",
        "    except ValueError:\n",
        "        # Skip segments that don't have the expected format\n",
        "        print(f\"Warning: Skipping segment with unexpected format: {segment_str}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    #check if the current segment should be merged with the previous one\n",
        "    if last_speaker is not None and speaker == last_speaker:\n",
        "        #extend the end time of the last segment\n",
        "        last_end = end_time\n",
        "    else:\n",
        "        #if it's not the first iteration and there's a previous segment to save\n",
        "        if last_speaker is not None:\n",
        "            merged_segments.append((last_start, last_end, last_speaker))\n",
        "        #update last segment trackers\n",
        "        last_start, last_end, last_speaker = start_time, end_time, speaker\n",
        "\n",
        "  #add the last segment after exiting the loop\n",
        "  if last_speaker is not None:\n",
        "      merged_segments.append((last_start, last_end, last_speaker))\n",
        "\n",
        "  return merged_segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VukxtLDsDEMm",
        "outputId": "f0ded448-3085-4351-d44a-009bedfa809c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Using cached torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting setuptools>=40.8.0 (from triton==3.3.0->torch)\n",
            "  Using cached setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Using cached torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.3\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.3:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.26.2\n",
            "    Uninstalling nvidia-nccl-cu12-2.26.2:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.26.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.12.0\n",
            "    Uninstalling fsspec-2024.12.0:\n",
            "      Successfully uninstalled fsspec-2024.12.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.3.0\n",
            "    Uninstalling triton-3.3.0:\n",
            "      Successfully uninstalled triton-3.3.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.7.0\n",
            "    Uninstalling torch-2.7.0:\n",
            "      Successfully uninstalled torch-2.7.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.6 which is incompatible.\n",
            "nemo-toolkit 2.4.0rc0 requires fsspec==2024.12.0, but you have fsspec 2025.5.0 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.0 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.24.4 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pillow-11.2.1 setuptools-80.8.0 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 triton-3.3.0 typing-extensions-4.13.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "29555760a6e840b0a2df65cc8c46f8f9",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "mpmath",
                  "networkx",
                  "pkg_resources",
                  "sympy",
                  "torch",
                  "torchgen",
                  "triton"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaTbQ3KnEt4J",
        "outputId": "3ffa2707-a325-470b-817c-1921c2f473aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==2.1.0\n",
            "  Downloading numpy-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nemo-toolkit 2.4.0rc0 requires fsspec==2024.12.0, but you have fsspec 2025.5.0 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.0 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.24.4 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==2.1.0 --force-reinstall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v5vrNR3GuVr",
        "outputId": "f3b7a894-814e-4bca-c066-1c3f45923308"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nemo'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnemo\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msoundfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumPy version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39m__version__)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nemo'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import nemo\n",
        "import soundfile as sf\n",
        "\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"NeMo version:\", nemo.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f81348b8ba0542cdb2763928d93a68e7",
            "484541a9f1c04d96ad57402a8c8f0175",
            "95d29f110c644fe9b025dfe24e434393",
            "0b6ecf6641894c29bf156655cbed5d98",
            "5d1d98a967834446ba300e859cb9c0bf",
            "e778de75ebf1406ebaf06283b4dafc2f",
            "50a305584b7c4f8db50a9909a2e92447",
            "7f3541b6e0814bc8a04978b89f6bc6e9",
            "0dc114710ace4f428094f295fbda9222",
            "b11dccae1ccc459b8d7746a63cb6fcdb",
            "8ec69c4fb9bc4f12ba6b758225c050f2"
          ]
        },
        "id": "uTn0iPoeVPlx",
        "outputId": "7384ef23-1665-4701-e2bc-516c9efe6741"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nemo'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnemo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SortformerEncLabelModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# load model from Hugging Face model card directly (You need a Hugging Face token)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m diar_model \u001b[38;5;241m=\u001b[39m SortformerEncLabelModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvidia/diar_sortformer_4spk-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nemo'"
          ]
        }
      ],
      "source": [
        "from nemo.collections.asr.models import SortformerEncLabelModel\n",
        "\n",
        "# load model from Hugging Face model card directly (You need a Hugging Face token)\n",
        "diar_model = SortformerEncLabelModel.from_pretrained(\"nvidia/diar_sortformer_4spk-v1\")\n",
        "\n",
        "\n",
        "# switch to inference mode\n",
        "diar_model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TQPzwvUGq4SV"
      },
      "outputs": [],
      "source": [
        "audio_input=\"/content/drive/MyDrive/data/medical/4696599d-37fb-442b-bdae-27e3325771b5_caecc2042dce919b3fa39143f8a9473a_a9KTbuFt.wav\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "NU-yMVQF4Upm",
        "outputId": "4fd33f84-2675-4c15-cb04-e5060fe34ab1"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[0;32m----> 2\u001b[0m \u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_input\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/bio_ramp/lib/python3.9/site-packages/IPython/lib/display.py:129\u001b[0m, in \u001b[0;36mAudio.__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m Audio\u001b[38;5;241m.\u001b[39m_make_wav(data, rate, normalize)\n",
            "\u001b[0;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."
          ]
        }
      ],
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jzP4dFaYvEqn"
      },
      "outputs": [
        {
          "ename": "LibsndfileError",
          "evalue": "Error opening '/content/drive/MyDrive/data/medical/4696599d-37fb-442b-bdae-27e3325771b5_caecc2042dce919b3fa39143f8a9473a_a9KTbuFt.wav': System error.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msoundfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m audio_signal, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_input\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/bio_ramp/lib/python3.9/site-packages/soundfile.py:305\u001b[0m, in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(file, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, always_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    220\u001b[0m          fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m          \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, endian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Provide audio data from a sound file as NumPy array.\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    By default, the whole file is read from the beginning, but the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m \n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    307\u001b[0m         frames \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m_prepare_read(start, stop, frames)\n\u001b[1;32m    308\u001b[0m         data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(frames, dtype, always_2d, fill_value, out)\n",
            "File \u001b[0;32m~/miniconda3/envs/bio_ramp/lib/python3.9/site-packages/soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bitrate_mode \u001b[38;5;241m=\u001b[39m bitrate_mode\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/bio_ramp/lib/python3.9/site-packages/soundfile.py:1265\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/content/drive/MyDrive/data/medical/4696599d-37fb-442b-bdae-27e3325771b5_caecc2042dce919b3fa39143f8a9473a_a9KTbuFt.wav': System error."
          ]
        }
      ],
      "source": [
        "import soundfile as sf\n",
        "audio_signal, sample_rate = sf.read(audio_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_WX0IpOUwnI8"
      },
      "outputs": [
        {
          "ename": "LibsndfileError",
          "evalue": "Error opening '/content/drive/MyDrive/data/medical/4696599d-37fb-442b-bdae-27e3325771b5_caecc2042dce919b3fa39143f8a9473a_a9KTbuFt.wav': System error.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Read stereo file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m audio, sr \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_input\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# audio.shape = (samples, 2)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert to mono by averaging channels\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(audio\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[0;32m~/miniconda3/envs/bio_ramp/lib/python3.9/site-packages/soundfile.py:305\u001b[0m, in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(file, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, always_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    220\u001b[0m          fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m          \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, endian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Provide audio data from a sound file as NumPy array.\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    By default, the whole file is read from the beginning, but the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m \n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    307\u001b[0m         frames \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m_prepare_read(start, stop, frames)\n\u001b[1;32m    308\u001b[0m         data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(frames, dtype, always_2d, fill_value, out)\n",
            "File \u001b[0;32m~/miniconda3/envs/bio_ramp/lib/python3.9/site-packages/soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bitrate_mode \u001b[38;5;241m=\u001b[39m bitrate_mode\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/bio_ramp/lib/python3.9/site-packages/soundfile.py:1265\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_ptr \u001b[38;5;241m==\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;66;03m# get the actual error code\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/content/drive/MyDrive/data/medical/4696599d-37fb-442b-bdae-27e3325771b5_caecc2042dce919b3fa39143f8a9473a_a9KTbuFt.wav': System error."
          ]
        }
      ],
      "source": [
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "# Read stereo file\n",
        "audio, sr = sf.read(audio_input)  # audio.shape = (samples, 2)\n",
        "\n",
        "# Convert to mono by averaging channels\n",
        "if len(audio.shape) == 2:\n",
        "    audio = np.mean(audio, axis=1)\n",
        "\n",
        "# Save as mono WAV\n",
        "sf.write('mono_audio.wav', audio, sr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAl9i4v7rJtH",
        "outputId": "5cbcf411-66c2-40a8-a4b5-2b8a2574389b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'diar_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predicted_segments \u001b[38;5;241m=\u001b[39m \u001b[43mdiar_model\u001b[49m\u001b[38;5;241m.\u001b[39mdiarize(audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmono_audio.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#pred_segments = merge_consecutive_segments(diarization)\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'diar_model' is not defined"
          ]
        }
      ],
      "source": [
        "predicted_segments = diar_model.diarize(audio='mono_audio.wav', batch_size=1)\n",
        "\n",
        "#pred_segments = merge_consecutive_segments(diarization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja6CivhH03bb"
      },
      "outputs": [],
      "source": [
        "merged_segments = merge_consecutive_segments(predicted_segments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF6xaQCPxUSY",
        "outputId": "c2eb7bc9-7b05-40a0-ecb3-79f434136211"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'predicted_segments' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredicted_segments\u001b[49m)\n\u001b[1;32m      2\u001b[0m unique_speakers \u001b[38;5;241m=\u001b[39m {chunk\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m predicted_segments[\u001b[38;5;241m0\u001b[39m]}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_speakers)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predicted_segments' is not defined"
          ]
        }
      ],
      "source": [
        "print(predicted_segments)\n",
        "unique_speakers = {chunk.split(\" \")[2] for chunk in predicted_segments[0]}\n",
        "print(unique_speakers)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bio_ramp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b6ecf6641894c29bf156655cbed5d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b11dccae1ccc459b8d7746a63cb6fcdb",
            "placeholder": "​",
            "style": "IPY_MODEL_8ec69c4fb9bc4f12ba6b758225c050f2",
            "value": " 493M/493M [00:06&lt;00:00, 91.7MB/s]"
          }
        },
        "0dc114710ace4f428094f295fbda9222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "484541a9f1c04d96ad57402a8c8f0175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e778de75ebf1406ebaf06283b4dafc2f",
            "placeholder": "​",
            "style": "IPY_MODEL_50a305584b7c4f8db50a9909a2e92447",
            "value": "diar_sortformer_4spk-v1.nemo: 100%"
          }
        },
        "50a305584b7c4f8db50a9909a2e92447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d1d98a967834446ba300e859cb9c0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f3541b6e0814bc8a04978b89f6bc6e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec69c4fb9bc4f12ba6b758225c050f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d29f110c644fe9b025dfe24e434393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3541b6e0814bc8a04978b89f6bc6e9",
            "max": 493434880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dc114710ace4f428094f295fbda9222",
            "value": 493434880
          }
        },
        "b11dccae1ccc459b8d7746a63cb6fcdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e778de75ebf1406ebaf06283b4dafc2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81348b8ba0542cdb2763928d93a68e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_484541a9f1c04d96ad57402a8c8f0175",
              "IPY_MODEL_95d29f110c644fe9b025dfe24e434393",
              "IPY_MODEL_0b6ecf6641894c29bf156655cbed5d98"
            ],
            "layout": "IPY_MODEL_5d1d98a967834446ba300e859cb9c0bf"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
