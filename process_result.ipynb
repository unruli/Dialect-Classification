{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00c29bd",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda6142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio\n",
    "from pyannote.core import Annotation, Segment\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a354b",
   "metadata": {},
   "source": [
    "## Work on CAM++ Diarization file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "257bfe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read can_plus csv file\n",
    "can_plus = pd.read_csv('Diarization results/can_plus_diarized_output.csv')\n",
    "sortformer_diarization = pd.read_csv('Diarization results/sortformer_diarization.csv')\n",
    "\n",
    "# Add 'audio_keep' column to can_plus if 'audio_id' in can_plus exists in sortformer_diarization\n",
    "can_plus['audio_keep'] = can_plus['audio_id'].isin(sortformer_diarization['audio_id'])\n",
    "\n",
    "# Copy 'transcript' from sortformer_diarization to can_plus where 'audio_id' matches\n",
    "can_plus['transcript'] = can_plus['audio_id'].map(sortformer_diarization.set_index('audio_id')['transcript'])\n",
    "\n",
    "# Filter can_plus to keep only rows where 'audio_keep' is True\n",
    "can_plus = can_plus[can_plus['audio_keep']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c2a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the {'text': ...} wrapper if present in each pred_segment\n",
    "for i, row in can_plus.iterrows():\n",
    "    seg = row['pred_segment']\n",
    "    # If seg is a string, try to eval to dict/list\n",
    "    if isinstance(seg, str):\n",
    "        try:\n",
    "            seg = eval(seg)\n",
    "        except Exception:\n",
    "            seg = seg\n",
    "    # If seg is a dict with 'text' key, extract it\n",
    "    if isinstance(seg, dict) and 'text' in seg:\n",
    "        segments_list = seg['text']\n",
    "    elif isinstance(seg, list):\n",
    "        segments_list = seg\n",
    "    else:\n",
    "        segments_list = []\n",
    "    formatted_segments = []\n",
    "    for s in segments_list:\n",
    "        # If segment is a list/tuple of length 3, convert to tuple\n",
    "        if isinstance(s, (list, tuple)) and len(s) == 3:\n",
    "            start, end, speaker = s\n",
    "            # Convert numpy types to float/int/str\n",
    "            try:\n",
    "                start = float(start)\n",
    "                end = float(end)\n",
    "                speaker = str(speaker)\n",
    "            except Exception:\n",
    "                pass\n",
    "            formatted_segments.append((start, end, speaker))\n",
    "        # If segment is a string, try to split\n",
    "        elif isinstance(s, str):\n",
    "            parts = s.split()\n",
    "            if len(parts) >= 3:\n",
    "                formatted_segments.append((float(parts[0]), float(parts[1]), parts[2]))\n",
    "    formatted_segments.sort(key=lambda x: x[0])\n",
    "    can_plus.at[i, 'pred_segment'] = formatted_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97e663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_seconds(timestamp):\n",
    "    # Split the timestamp into minutes, seconds, and milliseconds\n",
    "    minutes, seconds, milliseconds = map(float, timestamp.split(':'))\n",
    "    # Convert the time to seconds (including fractional part from milliseconds)\n",
    "    total_seconds = minutes * 60 + seconds + milliseconds / 1000\n",
    "    return total_seconds\n",
    "\n",
    "\n",
    "def extract_segments(transcript):\n",
    "    # Regular expression to match the timestamp and speaker tag\n",
    "    timestamp_pattern = r'(\\d{2}:\\d{2}:\\d{2})'\n",
    "    speaker_pattern = r'\\[([^\\]]+)\\]'\n",
    "\n",
    "    lines = transcript.strip().splitlines()\n",
    "    segments = []\n",
    "\n",
    "    start_time = None\n",
    "    speaker_tag = None\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        if re.match(timestamp_pattern, lines[i]):  # Line is a timestamp\n",
    "            if start_time and speaker_tag:\n",
    "                # If we have both start and speaker, the current timestamp is the end time\n",
    "                end_time = convert_time_to_seconds(lines[i])\n",
    "                segments.append((start_time, end_time, speaker_tag))\n",
    "                start_time = None\n",
    "                speaker_tag = None\n",
    "            # Set the new start time, converting to seconds\n",
    "            start_time = convert_time_to_seconds(lines[i])\n",
    "        elif re.match(speaker_pattern, lines[i]):  # Line contains a speaker tag\n",
    "            speaker_tag = re.findall(speaker_pattern, lines[i])[0]\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d61a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure new line before speaker tags\n",
    "can_plus['transcript'] = can_plus['transcript'].apply(lambda x: str(x).replace('[', '\\r\\n['))\n",
    "can_plus['ref_segments'] = can_plus['transcript'].apply(lambda x: extract_segments(x))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "can_plus.to_csv('/home/kelechi/Dialect-Classification/Diarization results/CAM_Plus_plus_diarization.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b95f42",
   "metadata": {},
   "source": [
    "## Read other model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b416890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files\n",
    "assemblyai = pd.read_csv('Diarization results/assemblyai_diarization_der_0.1272_30.csv')\n",
    "deepgram = pd.read_csv('Diarization results/deepgram_diarization_der_0.1421_30.csv')\n",
    "sortformer = pd.read_csv('Diarization results/sortformer_diarization.csv')\n",
    "pyannote = pd.read_csv('Diarization results/pyannote_diarization_der_0.2130_30.csv')\n",
    "soniox = pd.read_csv('Diarization results/soniox_diarization_der_0.2005_30.csv')\n",
    "reverb = pd.read_csv('Diarization results/reverb_diarization_der_0.2687_30.csv')\n",
    "cam = pd.read_csv('Diarization results/CAM_Plus_plus_diarization.csv')\n",
    "\n",
    "# Select only rows [0:31] of reverb\n",
    "reverb = reverb.iloc[0:31]\n",
    "# Filter out rows where 'audio_id' is nan in reverb\n",
    "reverb = reverb[reverb['audio_id'].notna()]\n",
    "\n",
    "#Rename 'pred_segment' to 'pred_segments' in cam\n",
    "cam.rename(columns={'pred_segment': 'pred_segments'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd0670",
   "metadata": {},
   "source": [
    "## Edit speaker tagging in pred_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c655207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def parse_segments(cell):\n",
    "    # If already a list of tuples, return as is\n",
    "    if isinstance(cell, list) and all(isinstance(x, tuple) for x in cell):\n",
    "        return cell\n",
    "    # If it's a list of single characters, join and eval\n",
    "    if isinstance(cell, list):\n",
    "        cell = ''.join(cell)\n",
    "    # If it's a string, eval\n",
    "    if isinstance(cell, str):\n",
    "        try:\n",
    "            return ast.literal_eval(cell)\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def map_speaker_labels(segments):\n",
    "    mapped = []\n",
    "    for seg in segments:\n",
    "        if len(seg) == 3:\n",
    "            start, end, speaker = seg\n",
    "            if speaker == '0':\n",
    "                speaker = 'Speaker A'\n",
    "            elif speaker == '1':\n",
    "                speaker = 'Speaker B'\n",
    "            mapped.append((start, end, speaker))\n",
    "        else:\n",
    "            mapped.append(seg)\n",
    "    return mapped\n",
    "\n",
    "# Apply both functions to the column\n",
    "cam['pred_segments'] = cam['pred_segments'].apply(parse_segments).apply(map_speaker_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fa846",
   "metadata": {},
   "source": [
    "## Check if audio_id is same for all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7da10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All audio IDs match across the dataframes.\n"
     ]
    }
   ],
   "source": [
    "# Verify that 'audio_id' columns are the same across all dataframes, if successful print a message\n",
    "def verify_audio_ids(*dfs):\n",
    "    audio_ids = [set(df['audio_id']) for df in dfs]\n",
    "    if not all(audio_ids[0] == audio_id for audio_id in audio_ids):\n",
    "        raise ValueError(\"Audio IDs do not match across all dataframes.\")\n",
    "        # Print all mismatched audio IDs\n",
    "    else:\n",
    "        print(\"All audio IDs match across the dataframes.\")\n",
    "verify_audio_ids(assemblyai, deepgram, sortformer, pyannote, soniox, reverb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f7bdb",
   "metadata": {},
   "source": [
    "## DER Matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb09cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyannote_annotation(segments_list):\n",
    "    annotation = Annotation()\n",
    "    for start, end, speaker_tag in segments_list:\n",
    "        segment = Segment(start, end)\n",
    "        annotation[segment] = speaker_tag\n",
    "    return annotation\n",
    "\n",
    "der_metric = DiarizationErrorRate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f683c",
   "metadata": {},
   "source": [
    "## Calculate absolute DER for all domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b513973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing assemblyai (ALL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/30 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 30/30 [00:00<00:00, 132.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 12.72%\n",
      "\n",
      "Processing deepgram (ALL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 30/30 [00:00<00:00, 128.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 14.21%\n",
      "\n",
      "Processing sortformer (ALL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 30/30 [00:00<00:00, 38.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 26.82%\n",
      "\n",
      "Processing pyannote (ALL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 30/30 [00:00<00:00, 147.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 21.30%\n",
      "\n",
      "Processing soniox (ALL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 30/30 [00:00<00:00, 180.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 20.05%\n",
      "\n",
      "Processing reverb (ALL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 30/30 [00:00<00:00, 148.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 20.23%\n",
      "\n",
      "Processing cam (ALL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 30/30 [00:00<00:00, 113.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 19.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_der_for_dataset(df, ref_col='ref_segments', pred_col='pred_segments'):\n",
    "    results = []\n",
    "    der_metric = DiarizationErrorRate()\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
    "        if not (isinstance(row[ref_col], (str, list)) and isinstance(row[pred_col], (str, list))):\n",
    "            continue\n",
    "        ref_annotation = create_pyannote_annotation(eval(row[ref_col]) if isinstance(row[ref_col], str) else row[ref_col])\n",
    "        pred_annotation = create_pyannote_annotation(eval(row[pred_col]) if isinstance(row[pred_col], str) else row[pred_col])\n",
    "        der = der_metric(ref_annotation, pred_annotation)\n",
    "        results.append({'audio_id': row['audio_id'], 'DER': der})\n",
    "    abs_der = abs(der_metric)\n",
    "    print(f\"Absolute DER for dataset: {100 * abs_der:.2f}%\")\n",
    "    return pd.DataFrame(results), abs_der\n",
    "\n",
    "datasets = {\n",
    "    'assemblyai': assemblyai,\n",
    "    'deepgram': deepgram,\n",
    "    'sortformer': sortformer,\n",
    "    'pyannote': pyannote,\n",
    "    'soniox': soniox,\n",
    "    'reverb': reverb,\n",
    "    'cam': cam,\n",
    "}\n",
    "\n",
    "der_results_all = {}\n",
    "abs_ders_all = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nProcessing {name} (ALL DOMAIN)...\")\n",
    "    der_df, abs_der = compute_der_for_dataset(df)\n",
    "    der_results_all[name] = der_df\n",
    "    abs_ders_all[name] = abs_der\n",
    "\n",
    "abs_der_df_all = pd.DataFrame.from_dict(abs_ders_all, orient='index', columns=['Absolute DER (All Domain)']).reset_index().rename(columns={'index': 'model'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d5fa0",
   "metadata": {},
   "source": [
    "## Absolute DER for Medical Domain Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd84f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing assemblyai (MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/9 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 9/9 [00:00<00:00, 62.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 25.68%\n",
      "\n",
      "Processing deepgram (MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/9 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 9/9 [00:00<00:00, 71.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 29.35%\n",
      "\n",
      "Processing sortformer (MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/9 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 9/9 [00:00<00:00, 33.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 39.64%\n",
      "\n",
      "Processing pyannote (MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/9 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 9/9 [00:00<00:00, 78.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 31.46%\n",
      "\n",
      "Processing soniox (MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/9 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 9/9 [00:00<00:00, 87.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 42.16%\n",
      "\n",
      "Processing reverb (MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/9 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 9/9 [00:00<00:00, 78.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 31.46%\n",
      "\n",
      "Processing cam (MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/9 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 9/9 [00:00<00:00, 66.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 34.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def filter_by_domain(df, domain='OSCE-Doctor-Patient'):\n",
    "    return df[df['domain'] == domain].reset_index(drop=True)\n",
    "\n",
    "filtered_datasets_medical = {name: filter_by_domain(df) for name, df in datasets.items()}\n",
    "\n",
    "der_results_medical = {}\n",
    "abs_ders_medical = {}\n",
    "medical_audio = []\n",
    "\n",
    "for name, df in filtered_datasets_medical.items():\n",
    "    print(f\"\\nProcessing {name} (MEDICAL DOMAIN)...\")\n",
    "    der_df, abs_der = compute_der_for_dataset(df)\n",
    "    der_df['model'] = name\n",
    "    medical_audio.append(der_df)\n",
    "    der_results_medical[name] = der_df\n",
    "    abs_ders_medical[name] = abs_der\n",
    "\n",
    "medical_audio = pd.concat(medical_audio, ignore_index=True)\n",
    "abs_der_df_medical = pd.DataFrame.from_dict(abs_ders_medical, orient='index', columns=['Medical Absolute DER']).reset_index().rename(columns={'index': 'model'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ad020",
   "metadata": {},
   "source": [
    "## Absolute DER for Non-Medical Domain Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b267b634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing assemblyai (NON-MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/21 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 21/21 [00:00<00:00, 235.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 9.91%\n",
      "\n",
      "Processing deepgram (NON-MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/21 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 21/21 [00:00<00:00, 206.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 10.92%\n",
      "\n",
      "Processing sortformer (NON-MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/21 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 21/21 [00:00<00:00, 41.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 24.04%\n",
      "\n",
      "Processing pyannote (NON-MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/21 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 21/21 [00:00<00:00, 230.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 19.09%\n",
      "\n",
      "Processing soniox (NON-MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/21 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 21/21 [00:00<00:00, 327.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 15.24%\n",
      "\n",
      "Processing reverb (NON-MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/21 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 21/21 [00:00<00:00, 237.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 17.68%\n",
      "\n",
      "Processing cam (NON-MEDICAL DOMAIN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/21 [00:00<?, ?it/s]/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
      "  warnings.warn(\n",
      "Processing: 100%|██████████| 21/21 [00:00<00:00, 159.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute DER for dataset: 16.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter all datasets for 'Chit-Chat-NG' domain\n",
    "def filter_by_domain(df, domain='OSCE-Doctor-Patient'):\n",
    "    return df[df['domain'] != domain].reset_index(drop=True)\n",
    "\n",
    "filtered_datasets_non_medical = {name: filter_by_domain(df) for name, df in datasets.items()}\n",
    "\n",
    "der_results_non_medical = {}\n",
    "abs_ders_non_medical = {}\n",
    "non_medical_audio = []\n",
    "\n",
    "for name, df in filtered_datasets_non_medical.items():\n",
    "    print(f\"\\nProcessing {name} (NON-MEDICAL DOMAIN)...\")\n",
    "    der_df, abs_der = compute_der_for_dataset(df)\n",
    "    der_df['model'] = name\n",
    "    non_medical_audio.append(der_df)\n",
    "    der_results_non_medical[name] = der_df\n",
    "    abs_ders_non_medical[name] = abs_der\n",
    "\n",
    "non_medical_audio = pd.concat(non_medical_audio, ignore_index=True)\n",
    "abs_der_df_non_medical = pd.DataFrame.from_dict(abs_ders_non_medical, orient='index', columns=['Non-Medical Absolute DER']).reset_index().rename(columns={'index': 'model'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0902b",
   "metadata": {},
   "source": [
    "## View all doamin, medical doamain and general domain files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae6f89cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Absolute DERs across domains:\n",
      "        model  Absolute DER (All Domain)  Medical Absolute DER  \\\n",
      "0  assemblyai                   0.127220              0.256756   \n",
      "1         cam                   0.195766              0.346428   \n",
      "2    deepgram                   0.142089              0.293510   \n",
      "3    pyannote                   0.213007              0.314621   \n",
      "4      reverb                   0.202347              0.314621   \n",
      "5      soniox                   0.200471              0.421604   \n",
      "6  sortformer                   0.268240              0.396392   \n",
      "\n",
      "   Non-Medical Absolute DER  \n",
      "0                  0.099077  \n",
      "1                  0.163033  \n",
      "2                  0.109191  \n",
      "3                  0.190930  \n",
      "4                  0.176771  \n",
      "5                  0.152428  \n",
      "6                  0.240398  \n"
     ]
    }
   ],
   "source": [
    "# --- DISPLAY ---\n",
    "# print(\"\\nAbsolute DERs for ALL DOMAIN datasets:\")\n",
    "# print(abs_der_df_all)\n",
    "\n",
    "# print(\"\\nAbsolute DERs for MEDICAL DOMAIN datasets:\")\n",
    "# print(abs_der_df_medical)\n",
    "\n",
    "# print(\"\\nAbsolute DERs for NON-MEDICAL DOMAIN datasets:\")\n",
    "# print(abs_der_df_non_medical)\n",
    "\n",
    "# Print a joint DataFrame with all absolute DERs, including all domains\n",
    "all_abs_der_df = pd.merge(abs_der_df_all, abs_der_df_medical, on='model', how='outer')\n",
    "all_abs_der_df = pd.merge(all_abs_der_df, abs_der_df_non_medical, on='model', how='outer')\n",
    "print(\"\\nAll Absolute DERs across domains:\")\n",
    "print(all_abs_der_df)\n",
    "\n",
    "# Save all absolute DERs to a CSV file\n",
    "all_abs_der_df.to_csv('Diarization results/absolute_der_all_domains_and_models.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
