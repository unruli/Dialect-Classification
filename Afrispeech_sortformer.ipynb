{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PIP Install (Only Run if not installed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install editdistance\n",
        "# %pip install datasets\n",
        "# %pip install lightning\n",
        "# %pip install webdataset\n",
        "# %pip install jiwer\n",
        "# %pip install einops\n",
        "# %pip install lhotse\n",
        "# %pip install transformers\n",
        "# %pip install sentencepiece\n",
        "# %pip install librosa\n",
        "# %pip install pyannote.audio\n",
        "# %pip install braceexpand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Libreries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy version: 1.26.3\n",
            "Torch version: 2.3.1+cu118\n",
            "NeMo version: 2.3.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import nemo \n",
        "\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Audio\n",
        "from pyannote.core import Annotation, Segment\n",
        "from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"NeMo version:\", nemo.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Input CSV File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Read csv file\n",
        "df = pd.read_csv('/home/kelechi/Dialect-Classification/Diarization results/assemblyai_diarization_der_0.1272_30.csv')\n",
        "\n",
        "input_csv = pd.read_csv('/home/kelechi/Dialect-Classification/data/dir_dataset/afrispeech_dialog_v1_47.csv')\n",
        "\n",
        "# Modify 'path' column to include the full path to remove data/ and change to data/dir_dataset/\n",
        "input_csv['path'] = input_csv['path'].apply(lambda x: x.replace('data/', 'data/dir_dataset/'))\n",
        "\n",
        "\n",
        "#Add a column 'keep' if audio_id in df['audio_id'] exists in input_csv['audio_id']\n",
        "input_csv['keep'] = input_csv['audio_id'].isin(df['audio_id'])\n",
        "\n",
        "# Select only rows where 'keep' is True\n",
        "input_csv = input_csv[input_csv['keep']]\n",
        "\n",
        "\n",
        "# # select only row index 0 and 16, 17 18 and 19\n",
        "# input_csv = input_csv.iloc[[0, 1, 16, 17, 18, 19]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load dirarization model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "[NeMo W 2025-05-27 16:01:59 modelPT:180] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 4\n",
            "    session_len_sec: 90\n",
            "    soft_label_thres: 0.5\n",
            "    soft_targets: false\n",
            "    labels: null\n",
            "    batch_size: 4\n",
            "    shuffle: true\n",
            "    num_workers: 18\n",
            "    validation_mode: false\n",
            "    use_lhotse: false\n",
            "    use_bucketing: false\n",
            "    num_buckets: 10\n",
            "    bucket_duration_bins:\n",
            "    - 10\n",
            "    - 20\n",
            "    - 30\n",
            "    - 40\n",
            "    - 50\n",
            "    - 60\n",
            "    - 70\n",
            "    - 80\n",
            "    - 90\n",
            "    pin_memory: true\n",
            "    min_duration: 80\n",
            "    max_duration: 90\n",
            "    batch_duration: 400\n",
            "    quadratic_duration: 1200\n",
            "    bucket_buffer_size: 20000\n",
            "    shuffle_buffer_size: 10000\n",
            "    window_stride: 0.01\n",
            "    subsampling_factor: 8\n",
            "    \n",
            "[NeMo W 2025-05-27 16:01:59 modelPT:187] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 4\n",
            "    session_len_sec: 90\n",
            "    soft_label_thres: 0.5\n",
            "    soft_targets: false\n",
            "    labels: null\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    num_workers: 18\n",
            "    validation_mode: true\n",
            "    use_lhotse: false\n",
            "    use_bucketing: false\n",
            "    drop_last: false\n",
            "    pin_memory: true\n",
            "    window_stride: 0.01\n",
            "    subsampling_factor: 8\n",
            "    \n",
            "[NeMo W 2025-05-27 16:01:59 modelPT:194] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 4\n",
            "    session_len_sec: 90\n",
            "    soft_label_thres: 0.5\n",
            "    soft_targets: false\n",
            "    labels: null\n",
            "    batch_size: 4\n",
            "    shuffle: false\n",
            "    seq_eval_mode: true\n",
            "    num_workers: 18\n",
            "    validation_mode: true\n",
            "    use_lhotse: false\n",
            "    use_bucketing: false\n",
            "    drop_last: false\n",
            "    pin_memory: true\n",
            "    window_stride: 0.01\n",
            "    subsampling_factor: 8\n",
            "    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:01:59 features:305] PADDING: 16\n",
            "[NeMo I 2025-05-27 16:02:00 save_restore_connector:275] Model SortformerEncLabelModel was successfully restored from /home/kelechi/.cache/huggingface/hub/models--nvidia--diar_sortformer_4spk-v1/snapshots/4cb5954e59a1a6527e6ec061a0568b61efa8babd/diar_sortformer_4spk-v1.nemo.\n"
          ]
        }
      ],
      "source": [
        "from nemo.collections.asr.models import SortformerEncLabelModel\n",
        "\n",
        "# load model from Hugging Face model card directly (You need a Hugging Face token)\n",
        "diar_model = SortformerEncLabelModel.from_pretrained(\"nvidia/diar_sortformer_4spk-v1\")\n",
        "\n",
        "\n",
        "# switch to inference mode\n",
        "diar_model.eval()\n",
        "\n",
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Audio Files for Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reading audio files: 100%|██████████| 30/30 [00:03<00:00,  9.26it/s]\n"
          ]
        }
      ],
      "source": [
        "# Loop through all rows in input_csv and read each audio file\n",
        "audio_signals = []\n",
        "sample_rates = []\n",
        "\n",
        "for path in tqdm(input_csv['path'], desc=\"Reading audio files\"):\n",
        "    audio_signal, sample_rate = sf.read(path)\n",
        "    audio_signals.append(audio_signal)\n",
        "    sample_rates.append(sample_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View/Play Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for path in input_csv['path_']:\n",
        "    display(Audio(path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process Audio as Mono Audio File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loop through each audio signal in audio_signals and save as mono WAV\n",
        "for i, audio_signal in enumerate(audio_signals):\n",
        "    # Convert to mono if stereo\n",
        "    if len(audio_signal.shape) == 2:\n",
        "        mono_audio = np.mean(audio_signal, axis=1)\n",
        "    else:\n",
        "        mono_audio = audio_signal\n",
        "    # Save as mono WAV with unique filename\n",
        "    out_path = f\"mono_audio_{i}.wav\"\n",
        "    sf.write(out_path, mono_audio, sample_rates[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Dirazation on Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:20 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:21 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:22 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:22 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:23 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:24 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:24 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:25 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:02:26 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA OOM on file mono_audio_8.wav, retrying on CPU...\n",
            "[NeMo I 2025-05-27 16:02:27 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing: 100%|██████████| 1/1 [01:40<00:00, 100.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:04:07 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA OOM on file mono_audio_9.wav, retrying on CPU...\n",
            "[NeMo I 2025-05-27 16:04:08 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing: 100%|██████████| 1/1 [02:57<00:00, 177.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:07:06 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA OOM on file mono_audio_10.wav, retrying on CPU...\n",
            "[NeMo I 2025-05-27 16:07:06 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing: 100%|██████████| 1/1 [01:53<00:00, 113.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:09:00 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:09:01 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:09:02 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA OOM on file mono_audio_13.wav, retrying on CPU...\n",
            "[NeMo I 2025-05-27 16:09:03 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing: 100%|██████████| 1/1 [01:52<00:00, 112.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:10:56 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:10:57 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:10:59 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:11:01 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:11:03 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:11:04 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:11:05 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:11:06 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA OOM on file mono_audio_21.wav, retrying on CPU...\n",
            "[NeMo I 2025-05-27 16:11:07 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing: 100%|██████████| 1/1 [01:37<00:00, 97.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:12:44 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:12:47 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:12:48 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:12:49 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA OOM on file mono_audio_25.wav, retrying on CPU...\n",
            "[NeMo I 2025-05-27 16:12:49 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing: 100%|██████████| 1/1 [01:26<00:00, 86.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:14:16 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:14:16 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:14:17 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NeMo I 2025-05-27 16:14:19 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Diarizing:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA OOM on file mono_audio_29.wav, retrying on CPU...\n",
            "[NeMo I 2025-05-27 16:14:19 vad_utils:81] No postprocessing YAML file has been provided. Default postprocessing configurations will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Diarizing: 100%|██████████| 1/1 [01:26<00:00, 86.28s/it]\n"
          ]
        }
      ],
      "source": [
        "# Ensure the column exists before assignment\n",
        "input_csv['pred_segments'] = None\n",
        "\n",
        "for i in range(len(audio_signals)):\n",
        "    audio_path = f\"mono_audio_{i}.wav\"\n",
        "    try:\n",
        "        predicted_segments = diar_model.diarize(audio=audio_path, batch_size=1)\n",
        "    except RuntimeError as e:\n",
        "        if \"CUDA out of memory\" in str(e):\n",
        "            print(f\"CUDA OOM on file {audio_path}, retrying on CPU...\")\n",
        "            diar_model = diar_model.to('cpu')\n",
        "            predicted_segments = diar_model.diarize(audio=audio_path, batch_size=1)\n",
        "            diar_model = diar_model.to('cuda')\n",
        "        else:\n",
        "            raise\n",
        "    # If predicted_segments is a list of lists, extract the first element\n",
        "    if isinstance(predicted_segments, list) and len(predicted_segments) > 0 and isinstance(predicted_segments[0], list):\n",
        "        input_csv.at[input_csv.index[i], 'pred_segments'] = predicted_segments[0]\n",
        "    else:\n",
        "        input_csv.at[input_csv.index[i], 'pred_segments'] = predicted_segments\n",
        "    torch.cuda.empty_cache()  # Optional: clear CUDA cache after each file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reformart Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, row in input_csv.iterrows():\n",
        "    segments_list = row['pred_segments'] if isinstance(row['pred_segments'], list) and len(row['pred_segments']) > 0 else []\n",
        "    formatted_segments = []\n",
        "    for seg in segments_list:\n",
        "        parts = seg.split()\n",
        "        if len(parts) >= 3:\n",
        "            formatted_segments.append((float(parts[0]), float(parts[1]), parts[2]))\n",
        "    formatted_segments.sort(key=lambda x: x[0])\n",
        "    input_csv.at[i, 'pred_segments'] = formatted_segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input_csv['pred_segments'] = ''\n",
        "# for i, path_ in tqdm(enumerate(input_csv['path']), total=len(input_csv['path']), desc='Processing'):\n",
        "#   # res = transcribe(path_)\n",
        "#   # pred_segments = extract_segments(input_csv['results']['channels'][0]['alternatives'][0]['paragraphs']['paragraphs'])\n",
        "#   input_csv.at[i, 'pred_segments'] = pred_segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert Time to Seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_time_to_seconds(timestamp):\n",
        "    # Split the timestamp into minutes, seconds, and milliseconds\n",
        "    minutes, seconds, milliseconds = map(float, timestamp.split(':'))\n",
        "    # Convert the time to seconds (including fractional part from milliseconds)\n",
        "    total_seconds = minutes * 60 + seconds + milliseconds / 1000\n",
        "    return total_seconds\n",
        "\n",
        "\n",
        "def extract_segments(transcript):\n",
        "    # Regular expression to match the timestamp and speaker tag\n",
        "    timestamp_pattern = r'(\\d{2}:\\d{2}:\\d{2})'\n",
        "    speaker_pattern = r'\\[([^\\]]+)\\]'\n",
        "\n",
        "    lines = transcript.strip().splitlines()\n",
        "    segments = []\n",
        "\n",
        "    start_time = None\n",
        "    speaker_tag = None\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        if re.match(timestamp_pattern, lines[i]):  # Line is a timestamp\n",
        "            if start_time and speaker_tag:\n",
        "                # If we have both start and speaker, the current timestamp is the end time\n",
        "                end_time = convert_time_to_seconds(lines[i])\n",
        "                segments.append((start_time, end_time, speaker_tag))\n",
        "                start_time = None\n",
        "                speaker_tag = None\n",
        "            # Set the new start time, converting to seconds\n",
        "            start_time = convert_time_to_seconds(lines[i])\n",
        "        elif re.match(speaker_pattern, lines[i]):  # Line contains a speaker tag\n",
        "            speaker_tag = re.findall(speaker_pattern, lines[i])[0]\n",
        "\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtain Ref_segment from Transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ensure new line before speaker tags\n",
        "input_csv['transcript'] = input_csv['transcript'].apply(lambda x: str(x).replace('[', '\\r\\n['))\n",
        "input_csv['ref_segments'] = input_csv['transcript'].apply(lambda x: extract_segments(x))\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "input_csv.to_csv('/home/kelechi/Dialect-Classification/Diarization results/nemo_diarization.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DER Matrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_pyannote_annotation(segments_list):\n",
        "    annotation = Annotation()\n",
        "    for start, end, speaker_tag in segments_list:\n",
        "        segment = Segment(start, end)\n",
        "        annotation[segment] = speaker_tag\n",
        "    return annotation\n",
        "\n",
        "der_metric = DiarizationErrorRate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   0%|          | 0/30 [00:00<?, ?it/s][NeMo W 2025-05-27 16:24:28 nemo_logging:361] /home/kelechi/miniconda3/envs/nemo310/lib/python3.10/site-packages/pyannote/metrics/utils.py:200: UserWarning: 'uem' was approximated by the union of 'reference' and 'hypothesis' extents.\n",
            "      warnings.warn(\n",
            "    \n",
            "Processing:  13%|█▎        | 4/30 [00:00<00:00, 35.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DER: 38.83%\n",
            "DER: 34.85%\n",
            "DER: 39.28%\n",
            "DER: 48.34%\n",
            "DER: 30.83%\n",
            "DER: 42.99%\n",
            "DER: 27.56%\n",
            "DER: 35.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  43%|████▎     | 13/30 [00:00<00:00, 26.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DER: 48.36%\n",
            "DER: 25.83%\n",
            "DER: 29.42%\n",
            "DER: 54.14%\n",
            "DER: 11.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  53%|█████▎    | 16/30 [00:00<00:00, 21.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DER: 13.42%\n",
            "DER: 22.93%\n",
            "DER: 38.98%\n",
            "DER: 12.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:  73%|███████▎  | 22/30 [00:00<00:00, 28.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DER: 21.74%\n",
            "DER: 17.12%\n",
            "DER: 20.03%\n",
            "DER: 7.44%\n",
            "DER: 38.34%\n",
            "DER: 15.51%\n",
            "DER: 13.46%\n",
            "DER: 33.68%\n",
            "DER: 4.30%\n",
            "DER: 21.15%\n",
            "DER: 38.24%\n",
            "DER: 11.16%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 30/30 [00:00<00:00, 33.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DER: 51.83%\n",
            "Absolute DER for dataset: 26.82%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i, text in tqdm(enumerate(input_csv['transcript']), total=len(input_csv['transcript']), desc=\"Processing\"):\n",
        "    ref_annotation = create_pyannote_annotation(input_csv.iloc[i]['ref_segments'])\n",
        "    pred_annotation = create_pyannote_annotation(input_csv.iloc[i]['pred_segments'])\n",
        "    der = der_metric(ref_annotation, pred_annotation)\n",
        "    print(f\"DER: {100 * der:.2f}%\")\n",
        "#get abs value for whole dataset\n",
        "ds_der = abs(der_metric)\n",
        "print(f\"Absolute DER for dataset: {100 * ds_der:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nemo310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b6ecf6641894c29bf156655cbed5d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b11dccae1ccc459b8d7746a63cb6fcdb",
            "placeholder": "​",
            "style": "IPY_MODEL_8ec69c4fb9bc4f12ba6b758225c050f2",
            "value": " 493M/493M [00:06&lt;00:00, 91.7MB/s]"
          }
        },
        "0dc114710ace4f428094f295fbda9222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "484541a9f1c04d96ad57402a8c8f0175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e778de75ebf1406ebaf06283b4dafc2f",
            "placeholder": "​",
            "style": "IPY_MODEL_50a305584b7c4f8db50a9909a2e92447",
            "value": "diar_sortformer_4spk-v1.nemo: 100%"
          }
        },
        "50a305584b7c4f8db50a9909a2e92447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d1d98a967834446ba300e859cb9c0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f3541b6e0814bc8a04978b89f6bc6e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec69c4fb9bc4f12ba6b758225c050f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d29f110c644fe9b025dfe24e434393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3541b6e0814bc8a04978b89f6bc6e9",
            "max": 493434880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dc114710ace4f428094f295fbda9222",
            "value": 493434880
          }
        },
        "b11dccae1ccc459b8d7746a63cb6fcdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e778de75ebf1406ebaf06283b4dafc2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81348b8ba0542cdb2763928d93a68e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_484541a9f1c04d96ad57402a8c8f0175",
              "IPY_MODEL_95d29f110c644fe9b025dfe24e434393",
              "IPY_MODEL_0b6ecf6641894c29bf156655cbed5d98"
            ],
            "layout": "IPY_MODEL_5d1d98a967834446ba300e859cb9c0bf"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
